{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ed05bb-fe72-45c8-aaf4-f067ee02838e",
   "metadata": {},
   "source": [
    "# Classification using Deep Learning with Histogram data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13095d08-82fa-49dc-8613-e8d4d1320555",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f39eb1-6f50-40c3-8468-226c0c8ee6b4",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f576c9-784f-49d2-bf5d-6978edeb89d4",
   "metadata": {},
   "source": [
    "First, we’ll load the saved image and label data from the NumPy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d239dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Load training data\n",
    "train_images = np.load('data/train_images.npy')\n",
    "train_labels = np.load('data/train_labels.npy')\n",
    "val_images = np.load('data/val_images.npy')\n",
    "val_labels = np.load('data/val_labels.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a0d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Características das Imagens ===\n",
      "Shape do conjunto de treino: (9711, 512, 512, 3) (Amostras, Altura, Largura, Canais)\n",
      "Shape do conjunto de validação: (3237, 512, 512, 3) (Amostras, Altura, Largura, Canais)\n",
      "Resolução das imagens: (512, 512) pixels\n",
      "Número de imagens no conjunto de treino: 9711\n",
      "Número de imagens no conjunto de validação: 3237\n",
      "Tipo de dado das imagens: uint8\n",
      "Valores mínimo e máximo no dataset de treino: 0 a 255\n",
      "\n",
      "=== Distribuição das Classes no Conjunto de Treino ===\n",
      "Classe 0: 2149 amostras\n",
      "Classe 1: 635 amostras\n",
      "Classe 2: 1186 amostras\n",
      "Classe 3: 2140 amostras\n",
      "Classe 4: 3601 amostras\n",
      "\n",
      "=== Distribuição das Classes no Conjunto de Validação ===\n",
      "Classe 0: 727 amostras\n",
      "Classe 1: 222 amostras\n",
      "Classe 2: 421 amostras\n",
      "Classe 3: 721 amostras\n",
      "Classe 4: 1146 amostras\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Carregar os arquivos\n",
    "train_images = np.load('data/train_images.npy')\n",
    "train_labels = np.load('data/train_labels.npy')\n",
    "val_images = np.load('data/val_images.npy')\n",
    "val_labels = np.load('data/val_labels.npy')\n",
    "\n",
    "# Exibir informações das imagens\n",
    "print(\"=== Características das Imagens ===\")\n",
    "print(f\"Shape do conjunto de treino: {train_images.shape} (Amostras, Altura, Largura, Canais)\")\n",
    "print(f\"Shape do conjunto de validação: {val_images.shape} (Amostras, Altura, Largura, Canais)\")\n",
    "\n",
    "# Resolução das imagens (altura e largura)\n",
    "image_resolution = train_images.shape[1:3]  # Pegando as dimensões de altura e largura\n",
    "print(f\"Resolução das imagens: {image_resolution} pixels\")\n",
    "\n",
    "# Número total de imagens\n",
    "print(f\"Número de imagens no conjunto de treino: {train_images.shape[0]}\")\n",
    "print(f\"Número de imagens no conjunto de validação: {val_images.shape[0]}\")\n",
    "\n",
    "# Tipo de dado armazenado\n",
    "print(f\"Tipo de dado das imagens: {train_images.dtype}\")\n",
    "\n",
    "# Intervalo de valores das imagens\n",
    "print(f\"Valores mínimo e máximo no dataset de treino: {train_images.min()} a {train_images.max()}\")\n",
    "\n",
    "# Exibir algumas amostras de rótulos únicos e suas contagens no conjunto de treino\n",
    "unique_labels_train, counts_train = np.unique(train_labels, return_counts=True)\n",
    "print(\"\\n=== Distribuição das Classes no Conjunto de Treino ===\")\n",
    "for label, count in zip(unique_labels_train, counts_train):\n",
    "    print(f\"Classe {label}: {count} amostras\")\n",
    "\n",
    "# Exibir algumas amostras de rótulos únicos e suas contagens no conjunto de validação\n",
    "unique_labels_val, counts_val = np.unique(val_labels, return_counts=True)\n",
    "print(\"\\n=== Distribuição das Classes no Conjunto de Validação ===\")\n",
    "for label, count in zip(unique_labels_val, counts_val):\n",
    "    print(f\"Classe {label}: {count} amostras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d8f2e",
   "metadata": {},
   "source": [
    "## Juntando conjuntos de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b62c188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Características das Imagens ===\n",
      "Shape do conjunto combinado: (12948, 512, 512, 3) (Amostras, Altura, Largura, Canais)\n",
      "Resolução das imagens: (512, 512) pixels\n",
      "Número total de imagens: 12948\n",
      "Tipo de dado das imagens: uint8\n",
      "Valores mínimo e máximo no dataset combinado: 0 a 255\n",
      "\n",
      "=== Distribuição das Classes no Conjunto Combinado ===\n",
      "Classe 0: 2876 amostras\n",
      "Classe 1: 857 amostras\n",
      "Classe 2: 1607 amostras\n",
      "Classe 3: 2861 amostras\n",
      "Classe 4: 4747 amostras\n",
      "\n",
      "Dados salvos em: cached_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Carregar os arquivos\n",
    "train_images = np.load('data/train_images.npy')\n",
    "train_labels = np.load('data/train_labels.npy')\n",
    "val_images = np.load('data/val_images.npy')\n",
    "val_labels = np.load('data/val_labels.npy')\n",
    "\n",
    "# Criar diretório para salvar os dados somados\n",
    "cached_data_dir = 'cached_data'\n",
    "os.makedirs(cached_data_dir, exist_ok=True)\n",
    "\n",
    "# Concatenar os conjuntos de treino e validação\n",
    "all_images = np.concatenate((train_images, val_images), axis=0)\n",
    "all_labels = np.concatenate((train_labels, val_labels), axis=0)\n",
    "\n",
    "# Salvar os arquivos combinados\n",
    "np.save(os.path.join(cached_data_dir, 'all_images.npy'), all_images)\n",
    "np.save(os.path.join(cached_data_dir, 'all_labels.npy'), all_labels)\n",
    "\n",
    "# Exibir informações das imagens\n",
    "print(\"=== Características das Imagens ===\")\n",
    "print(f\"Shape do conjunto combinado: {all_images.shape} (Amostras, Altura, Largura, Canais)\")\n",
    "print(f\"Resolução das imagens: {all_images.shape[1:3]} pixels\")\n",
    "print(f\"Número total de imagens: {all_images.shape[0]}\")\n",
    "print(f\"Tipo de dado das imagens: {all_images.dtype}\")\n",
    "print(f\"Valores mínimo e máximo no dataset combinado: {all_images.min()} a {all_images.max()}\")\n",
    "\n",
    "# Exibir distribuição das classes\n",
    "unique_labels, counts = np.unique(all_labels, return_counts=True)\n",
    "print(\"\\n=== Distribuição das Classes no Conjunto Combinado ===\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Classe {label}: {count} amostras\")\n",
    "\n",
    "print(f\"\\nDados salvos em: {cached_data_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a739cd9",
   "metadata": {},
   "source": [
    "### Aplicando SMOTE para balancear classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "177ff15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Distribuição das Classes após SMOTE ===\n",
      "Classe 0: 4747 amostras\n",
      "Classe 1: 4747 amostras\n",
      "Classe 2: 4747 amostras\n",
      "Classe 3: 4747 amostras\n",
      "Classe 4: 4747 amostras\n",
      "\n",
      "Dados balanceados salvos em: cached_data/SMOTE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Diretórios\n",
    "smote_dir = os.path.join(cached_data_dir, \"SMOTE\")\n",
    "os.makedirs(smote_dir, exist_ok=True)\n",
    "\n",
    "# Carregar os dados\n",
    "all_images = np.load(os.path.join(cached_data_dir, \"all_images.npy\"))\n",
    "all_labels = np.load(os.path.join(cached_data_dir, \"all_labels.npy\"))\n",
    "\n",
    "# Reshape para formato 2D necessário para o SMOTE\n",
    "num_samples, height, width, channels = all_images.shape\n",
    "all_images_reshaped = all_images.reshape(num_samples, -1)  # Flatten imagens para (num_samples, features)\n",
    "\n",
    "# Aplicar SMOTE para balancear as classes\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(all_images_reshaped, all_labels)\n",
    "\n",
    "# Retornar ao formato original (altura, largura, canais)\n",
    "X_resampled = X_resampled.reshape(-1, height, width, channels)\n",
    "\n",
    "# Embaralhar os dados para evitar padrões sequenciais\n",
    "X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "# Salvar os novos arquivos balanceados\n",
    "np.save(os.path.join(smote_dir, \"all_images_smote.npy\"), X_resampled)\n",
    "np.save(os.path.join(smote_dir, \"all_labels_smote.npy\"), y_resampled)\n",
    "\n",
    "# Exibir distribuição das novas classes\n",
    "unique_labels, counts = np.unique(y_resampled, return_counts=True)\n",
    "print(\"\\n=== Distribuição das Classes após SMOTE ===\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Classe {label}: {count} amostras\")\n",
    "\n",
    "print(f\"\\nDados balanceados salvos em: {smote_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849d30b",
   "metadata": {},
   "source": [
    "### DIVIDINDO O CONJUNTO SOMADO E BALANCEANDO NA PROPORÇÃO 0.8 (TREINO)/ 0.2 (VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cebd811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Distribuição das Classes no Conjunto de Treino ===\n",
      "Classe 0: 3797 amostras\n",
      "Classe 1: 3797 amostras\n",
      "Classe 2: 3797 amostras\n",
      "Classe 3: 3797 amostras\n",
      "Classe 4: 3797 amostras\n",
      "\n",
      "=== Distribuição das Classes no Conjunto de Validação ===\n",
      "Classe 0: 950 amostras\n",
      "Classe 1: 950 amostras\n",
      "Classe 2: 950 amostras\n",
      "Classe 3: 950 amostras\n",
      "Classe 4: 950 amostras\n",
      "\n",
      "Dados salvos em:\n",
      "Treino -> cached_data/SMOTE_TREINO\n",
      "Validação -> cached_data/SMOTE_VALID\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diretórios de origem e destino\n",
    "base_dir = \"cached_data/SMOTE\"\n",
    "train_dir = \"cached_data/SMOTE_TREINO\"\n",
    "valid_dir = \"cached_data/SMOTE_VALID\"\n",
    "\n",
    "# Criar diretórios de saída\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "# Carregar os dados balanceados\n",
    "all_images = np.load(os.path.join(base_dir, \"all_images_smote.npy\"))\n",
    "all_labels = np.load(os.path.join(base_dir, \"all_labels_smote.npy\"))\n",
    "\n",
    "# Separar os dados por classe e dividir em 80% treino, 20% validação\n",
    "train_images_list, valid_images_list = [], []\n",
    "train_labels_list, valid_labels_list = [], []\n",
    "\n",
    "unique_labels = np.unique(all_labels)\n",
    "\n",
    "for label in unique_labels:\n",
    "    # Filtrar imagens e rótulos da classe atual\n",
    "    indices = np.where(all_labels == label)[0]\n",
    "    images_class = all_images[indices]\n",
    "    labels_class = all_labels[indices]\n",
    "    \n",
    "    # Divisão em treino (80%) e validação (20%)\n",
    "    train_images, valid_images, train_labels, valid_labels = train_test_split(\n",
    "        images_class, labels_class, test_size=0.2, random_state=42, stratify=labels_class\n",
    "    )\n",
    "    \n",
    "    # Armazenar os dados separados\n",
    "    train_images_list.append(train_images)\n",
    "    train_labels_list.append(train_labels)\n",
    "    valid_images_list.append(valid_images)\n",
    "    valid_labels_list.append(valid_labels)\n",
    "\n",
    "# Concatenar os dados de todas as classes\n",
    "train_images_final = np.concatenate(train_images_list, axis=0)\n",
    "train_labels_final = np.concatenate(train_labels_list, axis=0)\n",
    "valid_images_final = np.concatenate(valid_images_list, axis=0)\n",
    "valid_labels_final = np.concatenate(valid_labels_list, axis=0)\n",
    "\n",
    "# Salvar os arquivos divididos\n",
    "np.save(os.path.join(train_dir, \"train_images.npy\"), train_images_final)\n",
    "np.save(os.path.join(train_dir, \"train_labels.npy\"), train_labels_final)\n",
    "np.save(os.path.join(valid_dir, \"val_images.npy\"), valid_images_final)\n",
    "np.save(os.path.join(valid_dir, \"val_labels.npy\"), valid_labels_final)\n",
    "\n",
    "# Exibir distribuição final das classes\n",
    "unique_train, count_train = np.unique(train_labels_final, return_counts=True)\n",
    "unique_valid, count_valid = np.unique(valid_labels_final, return_counts=True)\n",
    "\n",
    "print(\"\\n=== Distribuição das Classes no Conjunto de Treino ===\")\n",
    "for label, count in zip(unique_train, count_train):\n",
    "    print(f\"Classe {label}: {count} amostras\")\n",
    "\n",
    "print(\"\\n=== Distribuição das Classes no Conjunto de Validação ===\")\n",
    "for label, count in zip(unique_valid, count_valid):\n",
    "    print(f\"Classe {label}: {count} amostras\")\n",
    "\n",
    "print(f\"\\nDados salvos em:\\nTreino -> {train_dir}\\nValidação -> {valid_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd4a8dd1-52ed-4514-8cd1-a59980fab45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "# Load training data\n",
    "# train_images = np.load('data/train_images.npy')\n",
    "# train_labels = np.load('data/train_labels.npy')\n",
    "# val_images = np.load('data/val_images.npy')\n",
    "# val_labels = np.load('data/val_labels.npy')\n",
    "\n",
    "train_images = np.load('cached_data/SMOTE_TREINO/train_images.npy')\n",
    "train_labels = np.load('cached_data/SMOTE_TREINO/train_labels.npy')\n",
    "val_images = np.load('cached_data/SMOTE_VALID/val_images.npy')\n",
    "val_labels = np.load('cached_data/SMOTE_VALID/val_labels.npy')\n",
    "\n",
    "# Define quantile levels (e.g., deciles for 10 bins)\n",
    "quantile_levels = np.linspace(0, 1, num=11)  # 0.0, 0.1, ..., 1.0\n",
    "bin_edges = []\n",
    "\n",
    "# Compute quantiles for each channel (R, G, B)\n",
    "for channel in range(3):\n",
    "    channel_pixels = train_images[:, :, :, channel].flatten()\n",
    "    edges = np.quantile(channel_pixels, quantile_levels)\n",
    "    bin_edges.append(edges)\n",
    "# Save bin_edges for later use (e.g., validation)\n",
    "np.save('cached_data/bin_edges.npy', bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "364bc9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created histograms from images\n",
      "train_images removed from memory.\n"
     ]
    }
   ],
   "source": [
    "def image_to_histogram(image, bin_edges):\n",
    "    features = []\n",
    "    for channel in range(3):\n",
    "        pixels = image[:, :, channel].flatten()\n",
    "        hist, _ = np.histogram(pixels, bins=bin_edges[channel])\n",
    "        hist = hist / len(pixels)  # Normalize to proportions\n",
    "        features.extend(hist)\n",
    "    return np.array(features)\n",
    "\n",
    "# Convert training images to histograms\n",
    "train_histograms = np.array([image_to_histogram(img, bin_edges) for img in train_images])\n",
    "print(\"Created histograms from images\")\n",
    "\n",
    "# Free memory\n",
    "del train_images\n",
    "gc.collect()\n",
    "print(\"train_images removed from memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953fc9a-d986-47e1-8872-213f8518cdb7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a46294-7dfd-46c0-9146-d53220c58dbb",
   "metadata": {},
   "source": [
    "### Train CubeCatNet DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c005cb-a745-4594-8aab-15b67e0fcdac",
   "metadata": {},
   "source": [
    "We will define and train a Dense Neural Network (DNN) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af7dbc5a-b183-4974-a3fd-7ce74c4fa66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/repos/CubeSat_ImageClassify/env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8282 - loss: 0.6168\n",
      "Epoch 2/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1250\n",
      "Epoch 3/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.1063\n",
      "Epoch 4/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step - accuracy: 0.9673 - loss: 0.0923\n",
      "Epoch 5/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9711 - loss: 0.0799\n",
      "Epoch 6/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.9738 - loss: 0.0718\n",
      "Epoch 7/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 0.9769 - loss: 0.0679\n",
      "Epoch 8/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 0.9788 - loss: 0.0614\n",
      "Epoch 9/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9790 - loss: 0.0590\n",
      "Epoch 10/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 977us/step - accuracy: 0.9806 - loss: 0.0567\n",
      "Epoch 11/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9806 - loss: 0.0523\n",
      "Epoch 12/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9820 - loss: 0.0493\n",
      "Epoch 13/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9808 - loss: 0.0504\n",
      "Epoch 14/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9836 - loss: 0.0452\n",
      "Epoch 15/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.9823 - loss: 0.0441\n",
      "Epoch 16/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9860 - loss: 0.0386\n",
      "Epoch 17/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.9851 - loss: 0.0389\n",
      "Epoch 18/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9853 - loss: 0.0377\n",
      "Epoch 19/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.9864 - loss: 0.0337\n",
      "Epoch 20/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.9878 - loss: 0.0328\n",
      "Epoch 21/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.9876 - loss: 0.0338\n",
      "Epoch 22/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.9883 - loss: 0.0324\n",
      "Epoch 23/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.9896 - loss: 0.0291\n",
      "Epoch 24/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.9901 - loss: 0.0256\n",
      "Epoch 25/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.9905 - loss: 0.0266\n",
      "Epoch 26/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.9906 - loss: 0.0262\n",
      "Epoch 27/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.9910 - loss: 0.0248\n",
      "Epoch 28/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.9903 - loss: 0.0256\n",
      "Epoch 29/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - accuracy: 0.9914 - loss: 0.0238\n",
      "Epoch 30/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.9905 - loss: 0.0233\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_histograms.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train with early stopping\n",
    "history = model.fit(\n",
    "    train_histograms, to_categorical(train_labels, 5),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[EarlyStopping(monitor='accuracy', patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2e982-af38-461e-86da-bfd9a901fe82",
   "metadata": {},
   "source": [
    "##### **Saving the DNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a123927-9d9a-4947-b9b7-1caee56ae0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dnn_histogram_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d81a325-322d-44be-bc36-7bea97175fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels removed from memory.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del train_labels\n",
    "gc.collect()\n",
    "print(\"train_labels removed from memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd15bddd-54b7-48a5-91cd-1acad907826a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499dfaae-6af1-456d-92dc-dcd1e5a4b7d0",
   "metadata": {},
   "source": [
    "### Deep learning: Validation set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "291c88b2-4fe2-4216-bcac-02966189bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = np.load('data/val_images.npy')  # Load image val data\n",
    "val_labels = np.load('data/val_labels.npy')  # Load label val data\n",
    "val_labels = to_categorical(val_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38b820a0-83c6-41f9-929a-9f3a67827904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step\n"
     ]
    }
   ],
   "source": [
    "with open('dnn_histogram_model.pkl', 'rb') as file:\n",
    "    cnn_loaded_model = pickle.load(file)\n",
    "    \n",
    "# Load precomputed bin edges\n",
    "bin_edges = np.load('cached_data/bin_edges.npy')\n",
    "\n",
    "# Convert validation images to histograms\n",
    "val_images = np.load('data/val_images.npy')\n",
    "val_histograms = np.array([image_to_histogram(img, bin_edges) for img in val_images])\n",
    "\n",
    "# Free memory\n",
    "del val_images\n",
    "gc.collect()\n",
    "\n",
    "# Now use histograms for prediction\n",
    "val_predictions = cnn_loaded_model.predict(val_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03f5a607-5aa3-4106-aeb7-f1dfbb534ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       727\n",
      "           1       1.00      1.00      1.00       222\n",
      "           2       1.00      1.00      1.00       421\n",
      "           3       0.98      0.99      0.99       721\n",
      "           4       1.00      1.00      1.00      1146\n",
      "\n",
      "    accuracy                           0.99      3237\n",
      "   macro avg       0.99      0.99      0.99      3237\n",
      "weighted avg       0.99      0.99      0.99      3237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Convert from one-hot or probability distributions to single integer class indices (not necessary for 1D array)\n",
    "#val_predictions = np.argmax(val_predictions, axis=1) \n",
    "#val_labels = np.argmax(val_labels, axis=1) \n",
    "\n",
    "\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_labels, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a057ecbb-bc27-4ec1-a658-3f589c64b5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "reversescale": false,
         "showscale": true,
         "type": "heatmap",
         "x": [
          "Blurry",
          "Corrupt",
          "Missing_Data",
          "Noisy",
          "Priority"
         ],
         "y": [
          "Blurry",
          "Corrupt",
          "Missing_Data",
          "Noisy",
          "Priority"
         ],
         "z": {
          "bdata": "yQIAAAEADQAAAAAA3gAAAAAAAAAAAAAApQEAAAAABwAAAAAAygIAAAAAAAAAAAAAegQ=",
          "dtype": "i2",
          "shape": "5, 5"
         }
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "713",
          "x": "Blurry",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Corrupt",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "1",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "13",
          "x": "Noisy",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Priority",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Blurry",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "222",
          "x": "Corrupt",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Noisy",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Priority",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Blurry",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Corrupt",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "421",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Noisy",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Priority",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "7",
          "x": "Blurry",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Corrupt",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "714",
          "x": "Noisy",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Priority",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Blurry",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Corrupt",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Noisy",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1146",
          "x": "Priority",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion Matrix with Class Names"
        },
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "top",
         "ticks": "",
         "title": {
          "text": "Predicted Label"
         }
        },
        "yaxis": {
         "dtick": 1,
         "ticks": "",
         "ticksuffix": "  ",
         "title": {
          "text": "True Label"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"]\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_predictions)\n",
    "\n",
    "# Create the heatmap\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    z=cm, \n",
    "    x=class_names, \n",
    "    y=class_names, \n",
    "    colorscale=\"Blues\",\n",
    "    showscale=True\n",
    ")\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    title=\"Confusion Matrix with Class Names\",\n",
    "    xaxis=dict(title=\"Predicted Label\"),\n",
    "    yaxis=dict(title=\"True Label\")\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd9ea9-aa11-4f94-be51-b406ff860735",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01be5fd-f911-410b-81e4-f0cd21f4cb4f",
   "metadata": {},
   "source": [
    "# Deep learning: testing with unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b614995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Histogram-Based Model:\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step\n",
      "Histogram Model Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       668\n",
      "           1       1.00      1.00      1.00       213\n",
      "           2       1.00      1.00      1.00       414\n",
      "           3       0.99      0.98      0.99       721\n",
      "           4       1.00      1.00      1.00      1221\n",
      "\n",
      "    accuracy                           0.99      3237\n",
      "   macro avg       0.99      0.99      0.99      3237\n",
      "weighted avg       0.99      0.99      0.99      3237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "def test_models():\n",
    "    # Load test data\n",
    "    test_images = np.load('data/test_images1.npy')\n",
    "    test_labels = np.load('data/test_labels.npy')\n",
    "    true_classes = test_labels  # Save original labels for reporting\n",
    "\n",
    "    # Test Histogram Model\n",
    "    print(\"\\nTesting Histogram-Based Model:\")\n",
    "    \n",
    "    # Load histogram model and bin edges\n",
    "    with open('dnn_histogram_model.pkl', 'rb') as f:  # Assuming you saved this separately\n",
    "        hist_model = pickle.load(f)\n",
    "    \n",
    "    bin_edges = np.load('cached_data/bin_edges.npy')\n",
    "    \n",
    "    # Convert test images to histograms\n",
    "    test_histograms = np.array([image_to_histogram(img, bin_edges) for img in test_images])\n",
    "    \n",
    "    # Predict with histograms\n",
    "    hist_pred_probs = hist_model.predict(test_histograms)\n",
    "    hist_pred_classes = np.argmax(hist_pred_probs, axis=1)\n",
    "    \n",
    "    # Generate report\n",
    "    print(\"Histogram Model Report:\")\n",
    "    print(classification_report(true_classes, hist_pred_classes))\n",
    "    \n",
    "    # Cleanup\n",
    "    del test_images, test_histograms, hist_model\n",
    "    gc.collect()\n",
    "\n",
    "def image_to_histogram(image, bin_edges):\n",
    "    \"\"\" Your existing histogram conversion function \"\"\"\n",
    "    features = []\n",
    "    for channel in range(3):\n",
    "        pixels = image[:, :, channel].flatten()\n",
    "        hist, _ = np.histogram(pixels, bins=bin_edges[channel])\n",
    "        hist = hist / len(pixels)  # Normalize\n",
    "        features.extend(hist)\n",
    "    return np.array(features)\n",
    "\n",
    "test_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9d935-fda3-4ea3-8b33-4d5bd7cefc3a",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
