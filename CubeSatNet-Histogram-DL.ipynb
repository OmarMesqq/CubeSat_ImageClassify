{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ed05bb-fe72-45c8-aaf4-f067ee02838e",
   "metadata": {},
   "source": [
    "# Classification using Deep Learning with Histogram data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13095d08-82fa-49dc-8613-e8d4d1320555",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f39eb1-6f50-40c3-8468-226c0c8ee6b4",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f576c9-784f-49d2-bf5d-6978edeb89d4",
   "metadata": {},
   "source": [
    "First, we’ll load the saved image and label data from the NumPy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d239dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "notebook_start_time = time.time()\n",
    "\n",
    "# Load training data\n",
    "train_images = np.load('data/train_images.npy')\n",
    "train_labels = np.load('data/train_labels.npy')\n",
    "val_images = np.load('data/val_images.npy')\n",
    "val_labels = np.load('data/val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a0d2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Image Characteristics ===\n",
      "Shape of training set: (9711, 512, 512, 3) (Samples, Height, Width, Channels)\n",
      "Shape of validation set: (3237, 512, 512, 3) (Samples, Height, Width, Channels)\n",
      "Image resolution: (512, 512) pixels\n",
      "Number of images in training set: 9711\n",
      "Number of images in validation set: 3237\n",
      "Data type of images: uint8\n",
      "Minimum and maximum values in training dataset: 0 to 255\n",
      "\n",
      "=== Class Distribution in Training Set ===\n",
      "Class 0: 2149 samples\n",
      "Class 1: 635 samples\n",
      "Class 2: 1186 samples\n",
      "Class 3: 2140 samples\n",
      "Class 4: 3601 samples\n",
      "\n",
      "=== Class Distribution in Validation Set ===\n",
      "Class 0: 727 samples\n",
      "Class 1: 222 samples\n",
      "Class 2: 421 samples\n",
      "Class 3: 721 samples\n",
      "Class 4: 1146 samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Display image information\n",
    "print(\"=== Image Characteristics ===\")\n",
    "print(f\"Shape of training set: {train_images.shape} (Samples, Height, Width, Channels)\")\n",
    "print(f\"Shape of validation set: {val_images.shape} (Samples, Height, Width, Channels)\")\n",
    "\n",
    "# Image resolution (height and width)\n",
    "image_resolution = train_images.shape[1:3]  # Taking height and width dimensions\n",
    "print(f\"Image resolution: {image_resolution} pixels\")\n",
    "\n",
    "# Total number of images\n",
    "print(f\"Number of images in training set: {train_images.shape[0]}\")\n",
    "print(f\"Number of images in validation set: {val_images.shape[0]}\")\n",
    "\n",
    "# Data type of the images\n",
    "print(f\"Data type of images: {train_images.dtype}\")\n",
    "\n",
    "# Range of values in the images\n",
    "print(f\"Minimum and maximum values in training dataset: {train_images.min()} to {train_images.max()}\")\n",
    "\n",
    "# Display some unique labels and their counts in the training set\n",
    "unique_labels_train, counts_train = np.unique(train_labels, return_counts=True)\n",
    "print(\"\\n=== Class Distribution in Training Set ===\")\n",
    "for label, count in zip(unique_labels_train, counts_train):\n",
    "    print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "# Display some unique labels and their counts in the validation set\n",
    "unique_labels_val, counts_val = np.unique(val_labels, return_counts=True)\n",
    "print(\"\\n=== Class Distribution in Validation Set ===\")\n",
    "for label, count in zip(unique_labels_val, counts_val):\n",
    "    print(f\"Class {label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d8f2e",
   "metadata": {},
   "source": [
    "## Combining training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b62c188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined files already exist. Loading from disk...\n",
      "=== Image Characteristics ===\n",
      "Shape of combined dataset: (12948, 512, 512, 3) (Samples, Height, Width, Channels)\n",
      "Image resolution: (512, 512) pixels\n",
      "Total number of images: 12948\n",
      "Data type of images: uint8\n",
      "Minimum and maximum values in combined dataset: 0 to 255\n",
      "\n",
      "=== Class Distribution in Combined Dataset ===\n",
      "Class 0: 2876 samples\n",
      "Class 1: 857 samples\n",
      "Class 2: 1607 samples\n",
      "Class 3: 2861 samples\n",
      "Class 4: 4747 samples\n",
      "\n",
      "Data saved in: cached_data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create directory to save the combined data\n",
    "cached_data_dir = 'cached_data'\n",
    "os.makedirs(cached_data_dir, exist_ok=True)\n",
    "\n",
    "# File paths for saved combined data\n",
    "all_images_path = os.path.join(cached_data_dir, 'all_images.npy')\n",
    "all_labels_path = os.path.join(cached_data_dir, 'all_labels.npy')\n",
    "\n",
    "# Check if combined files already exist\n",
    "if os.path.exists(all_images_path) and os.path.exists(all_labels_path):\n",
    "    print(\"Combined files already exist. Loading from disk...\")\n",
    "    all_images = np.load(all_images_path)\n",
    "    all_labels = np.load(all_labels_path)\n",
    "else:\n",
    "    print(\"Combined files do not exist. Concatenating data...\")\n",
    "    # Concatenate the training and validation sets\n",
    "    all_images = np.concatenate((train_images, val_images), axis=0)\n",
    "    all_labels = np.concatenate((train_labels, val_labels), axis=0)\n",
    "\n",
    "    # Save the combined files\n",
    "    np.save(all_images_path, all_images)\n",
    "    np.save(all_labels_path, all_labels)\n",
    "    print(\"Data concatenated and saved.\")\n",
    "\n",
    "# Display image information\n",
    "print(\"=== Image Characteristics ===\")\n",
    "print(f\"Shape of combined dataset: {all_images.shape} (Samples, Height, Width, Channels)\")\n",
    "print(f\"Image resolution: {all_images.shape[1:3]} pixels\")\n",
    "print(f\"Total number of images: {all_images.shape[0]}\")\n",
    "print(f\"Data type of images: {all_images.dtype}\")\n",
    "print(f\"Minimum and maximum values in combined dataset: {all_images.min()} to {all_images.max()}\")\n",
    "\n",
    "# Display class distribution\n",
    "unique_labels, counts = np.unique(all_labels, return_counts=True)\n",
    "print(\"\\n=== Class Distribution in Combined Dataset ===\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "print(f\"\\nData saved in: {cached_data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f29b6dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del train_images, train_labels, val_images, val_labels\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a739cd9",
   "metadata": {},
   "source": [
    "## Applying SMOTE for class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "177ff15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE files already exist. Loading from disk...\n",
      "\n",
      "=== Class Distribution after SMOTE ===\n",
      "Class 0: 4747 samples\n",
      "Class 1: 4747 samples\n",
      "Class 2: 4747 samples\n",
      "Class 3: 4747 samples\n",
      "Class 4: 4747 samples\n",
      "\n",
      "Balanced data saved in: cached_data/SMOTE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Directories\n",
    "smote_dir = os.path.join(cached_data_dir, \"SMOTE\")\n",
    "os.makedirs(smote_dir, exist_ok=True)\n",
    "\n",
    "# File paths for saved SMOTE data\n",
    "smote_images_path = os.path.join(smote_dir, \"all_images_smote.npy\")\n",
    "smote_labels_path = os.path.join(smote_dir, \"all_labels_smote.npy\")\n",
    "\n",
    "# Check if SMOTE files already exist\n",
    "if os.path.exists(smote_images_path) and os.path.exists(smote_labels_path):\n",
    "    print(\"SMOTE files already exist. Loading from disk...\")\n",
    "    X_resampled = np.load(smote_images_path)\n",
    "    y_resampled = np.load(smote_labels_path)\n",
    "else:\n",
    "    print(\"SMOTE files do not exist. Applying SMOTE...\")\n",
    "    # Reshape to 2D format required for SMOTE\n",
    "    num_samples, height, width, channels = all_images.shape\n",
    "    all_images_reshaped = all_images.reshape(num_samples, -1)  # Flatten images to (num_samples, features)\n",
    "\n",
    "    # Apply SMOTE to balance the classes\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(all_images_reshaped, all_labels)\n",
    "\n",
    "    # Reshape back to the original format (height, width, channels)\n",
    "    X_resampled = X_resampled.reshape(-1, height, width, channels)\n",
    "\n",
    "    # Shuffle the data to avoid sequential patterns\n",
    "    X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "    # Save the new balanced files\n",
    "    np.save(smote_images_path, X_resampled)\n",
    "    np.save(smote_labels_path, y_resampled)\n",
    "    print(\"SMOTE applied and files saved.\")\n",
    "\n",
    "# Display the distribution of the new classes\n",
    "unique_labels, counts = np.unique(y_resampled, return_counts=True)\n",
    "print(\"\\n=== Class Distribution after SMOTE ===\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "print(f\"\\nBalanced data saved in: {smote_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849d30b",
   "metadata": {},
   "source": [
    "## Splitting combined set in proportion 80% for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cebd811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split files already exist. Loading from disk...\n",
      "\n",
      "=== Class Distribution in Training Set ===\n",
      "Class 0: 3797 samples\n",
      "Class 1: 3797 samples\n",
      "Class 2: 3797 samples\n",
      "Class 3: 3797 samples\n",
      "Class 4: 3797 samples\n",
      "\n",
      "=== Class Distribution in Validation Set ===\n",
      "Class 0: 950 samples\n",
      "Class 1: 950 samples\n",
      "Class 2: 950 samples\n",
      "Class 3: 950 samples\n",
      "Class 4: 950 samples\n",
      "\n",
      "Data saved in:\n",
      "Training -> cached_data/SMOTE/training\n",
      "Validation -> cached_data/SMOTE/validation\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Source and destination directories\n",
    "train_dir = os.path.join(smote_dir, \"training\")\n",
    "valid_dir = os.path.join(smote_dir, \"validation\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(valid_dir, exist_ok=True)\n",
    "\n",
    "# File paths for saved split data\n",
    "train_images_path = os.path.join(train_dir, \"train_images.npy\")\n",
    "train_labels_path = os.path.join(train_dir, \"train_labels.npy\")\n",
    "val_images_path = os.path.join(valid_dir, \"val_images.npy\")\n",
    "val_labels_path = os.path.join(valid_dir, \"val_labels.npy\")\n",
    "\n",
    "# Check if split files already exist\n",
    "if (os.path.exists(train_images_path) and os.path.exists(train_labels_path) and\n",
    "    os.path.exists(val_images_path) and os.path.exists(val_labels_path)):\n",
    "    print(\"Split files already exist. Loading from disk...\")\n",
    "    train_images_final = np.load(train_images_path)\n",
    "    train_labels_final = np.load(train_labels_path)\n",
    "    valid_images_final = np.load(val_images_path)\n",
    "    valid_labels_final = np.load(val_labels_path)\n",
    "else:\n",
    "    print(\"Split files do not exist. Splitting data...\")\n",
    "    # Separate data by class and split into 80% training, 20% validation\n",
    "    train_images_list, valid_images_list = [], []\n",
    "    train_labels_list, valid_labels_list = [], []\n",
    "\n",
    "    unique_labels = np.unique(y_resampled)  # Use the resampled labels\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Filter images and labels for the current class\n",
    "        indices = np.where(y_resampled == label)[0]\n",
    "        images_class = X_resampled[indices]  # Use the resampled images\n",
    "        labels_class = y_resampled[indices]  # Use the resampled labels\n",
    "        \n",
    "        # Split into training (80%) and validation (20%)\n",
    "        train_images, valid_images, train_labels, valid_labels = train_test_split(\n",
    "            images_class, labels_class, test_size=0.2, random_state=42, stratify=labels_class\n",
    "        )\n",
    "        \n",
    "        # Store the separated data\n",
    "        train_images_list.append(train_images)\n",
    "        train_labels_list.append(train_labels)\n",
    "        valid_images_list.append(valid_images)\n",
    "        valid_labels_list.append(valid_labels)\n",
    "\n",
    "    # Concatenate data from all classes\n",
    "    train_images_final = np.concatenate(train_images_list, axis=0)\n",
    "    train_labels_final = np.concatenate(train_labels_list, axis=0)\n",
    "    valid_images_final = np.concatenate(valid_images_list, axis=0)\n",
    "    valid_labels_final = np.concatenate(valid_labels_list, axis=0)\n",
    "\n",
    "    # Save the split files\n",
    "    np.save(train_images_path, train_images_final)\n",
    "    np.save(train_labels_path, train_labels_final)\n",
    "    np.save(val_images_path, valid_images_final)\n",
    "    np.save(val_labels_path, valid_labels_final)\n",
    "    print(\"Data split and saved.\")\n",
    "\n",
    "# Display final class distribution\n",
    "unique_train, count_train = np.unique(train_labels_final, return_counts=True)\n",
    "unique_valid, count_valid = np.unique(valid_labels_final, return_counts=True)\n",
    "\n",
    "print(\"\\n=== Class Distribution in Training Set ===\")\n",
    "for label, count in zip(unique_train, count_train):\n",
    "    print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "print(\"\\n=== Class Distribution in Validation Set ===\")\n",
    "for label, count in zip(unique_valid, count_valid):\n",
    "    print(f\"Class {label}: {count} samples\")\n",
    "\n",
    "print(f\"\\nData saved in:\\nTraining -> {train_dir}\\nValidation -> {valid_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4a8dd1-52ed-4514-8cd1-a59980fab45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bin edges file already exists. Loading from disk...\n",
      "\n",
      "=== Bin Edges ===\n",
      "Channel 0: [  0.   0.   2.   3.   4.   5.   7.  26. 144. 253. 255.]\n",
      "Channel 1: [  0.   0.   1.   2.   2.   3.   5.  11.  56. 125. 255.]\n",
      "Channel 2: [  0.   0.   1.   2.   3.   3.   5.  12.  60. 123. 255.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the training data\n",
    "train_images = np.load(os.path.join(train_dir, 'train_images.npy'))\n",
    "train_labels = np.load(os.path.join(train_dir, 'train_labels.npy'))\n",
    "val_images = np.load(os.path.join(valid_dir, 'val_images.npy'))\n",
    "val_labels = np.load(os.path.join(valid_dir, 'val_labels.npy'))\n",
    "\n",
    "# File path for saved bin edges\n",
    "bin_edges_path = os.path.join(cached_data_dir, 'bin_edges.npy')\n",
    "\n",
    "# Check if bin edges file already exists\n",
    "if os.path.exists(bin_edges_path):\n",
    "    print(\"Bin edges file already exists. Loading from disk...\")\n",
    "    bin_edges = np.load(bin_edges_path, allow_pickle=True)\n",
    "else:\n",
    "    print(\"Bin edges file does not exist. Computing quantiles...\")\n",
    "    \n",
    "    # Define quantile levels (e.g., deciles for 10 bins)\n",
    "    quantile_levels = np.linspace(0, 1, num=11)  # 0.0, 0.1, ..., 1.0\n",
    "    bin_edges = []\n",
    "\n",
    "    # Compute quantiles for each channel (R, G, B)\n",
    "    for channel in range(3):\n",
    "        channel_pixels = train_images[:, :, :, channel].flatten()\n",
    "        edges = np.quantile(channel_pixels, quantile_levels)\n",
    "        bin_edges.append(edges)\n",
    "\n",
    "    # Save the computed bin edges\n",
    "    np.save(bin_edges_path, bin_edges)\n",
    "    print(\"Quantiles computed and bin edges saved.\")\n",
    "\n",
    "# Display the bin edges (optional)\n",
    "print(\"\\n=== Bin Edges ===\")\n",
    "for channel, edges in enumerate(bin_edges):\n",
    "    print(f\"Channel {channel}: {edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "364bc9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created histograms from images\n",
      "train_images removed from memory.\n"
     ]
    }
   ],
   "source": [
    "def image_to_histogram(image, bin_edges):\n",
    "    features = []\n",
    "    for channel in range(3):\n",
    "        pixels = image[:, :, channel].flatten()\n",
    "        hist, _ = np.histogram(pixels, bins=bin_edges[channel])\n",
    "        hist = hist / len(pixels)  # Normalize to proportions\n",
    "        features.extend(hist)\n",
    "    return np.array(features)\n",
    "\n",
    "# Convert training images to histograms\n",
    "train_histograms = np.array([image_to_histogram(img, bin_edges) for img in train_images])\n",
    "print(\"Created histograms from images\")\n",
    "\n",
    "# Free memory\n",
    "del train_images\n",
    "gc.collect()\n",
    "print(\"train_images removed from memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3953fc9a-d986-47e1-8872-213f8518cdb7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a46294-7dfd-46c0-9146-d53220c58dbb",
   "metadata": {},
   "source": [
    "### Train CubeSatNet DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c005cb-a745-4594-8aab-15b67e0fcdac",
   "metadata": {},
   "source": [
    "We will define and train a Dense Neural Network (DNN) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af7dbc5a-b183-4974-a3fd-7ce74c4fa66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 04:08:24.240378: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-22 04:08:24.519307: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-22 04:08:24.621816: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-22 04:08:24.821834: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-22 04:08:24.865772: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-22 04:08:25.143257: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-22 04:08:26.906267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omar/repos/CubeSat_ImageClassify/env/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 952us/step - accuracy: 0.8421 - loss: 0.6291\n",
      "Epoch 2/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9535 - loss: 0.1246\n",
      "Epoch 3/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.9633 - loss: 0.1010\n",
      "Epoch 4/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.9694 - loss: 0.0830\n",
      "Epoch 5/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.9716 - loss: 0.0785\n",
      "Epoch 6/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.9728 - loss: 0.0720\n",
      "Epoch 7/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.9767 - loss: 0.0625\n",
      "Epoch 8/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 875us/step - accuracy: 0.9808 - loss: 0.0550\n",
      "Epoch 9/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 0.9802 - loss: 0.0552\n",
      "Epoch 10/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842us/step - accuracy: 0.9801 - loss: 0.0515\n",
      "Epoch 11/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.9840 - loss: 0.0445\n",
      "Epoch 12/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.9812 - loss: 0.0486\n",
      "Epoch 13/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.9844 - loss: 0.0429\n",
      "Epoch 14/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.9850 - loss: 0.0377\n",
      "Epoch 15/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 846us/step - accuracy: 0.9844 - loss: 0.0402\n",
      "Epoch 16/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.9855 - loss: 0.0372\n",
      "Epoch 17/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 838us/step - accuracy: 0.9877 - loss: 0.0320\n",
      "Epoch 18/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 889us/step - accuracy: 0.9858 - loss: 0.0349\n",
      "Epoch 19/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.9877 - loss: 0.0356\n",
      "Epoch 20/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.9896 - loss: 0.0280\n",
      "Epoch 21/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - accuracy: 0.9889 - loss: 0.0306\n",
      "Epoch 22/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.9885 - loss: 0.0291\n",
      "Epoch 23/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 0.9891 - loss: 0.0281\n",
      "Epoch 24/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.9897 - loss: 0.0271\n",
      "Epoch 25/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.9906 - loss: 0.0248\n",
      "Epoch 26/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.9897 - loss: 0.0270\n",
      "Epoch 27/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.9907 - loss: 0.0251\n",
      "Epoch 28/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 0.9909 - loss: 0.0228\n",
      "Epoch 29/30\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.9911 - loss: 0.0224\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_histograms.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_histograms, to_categorical(train_labels, 5),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[EarlyStopping(monitor='accuracy', patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2e982-af38-461e-86da-bfd9a901fe82",
   "metadata": {},
   "source": [
    "##### **Saving the DNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a123927-9d9a-4947-b9b7-1caee56ae0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models/dnn_histogram_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d81a325-322d-44be-bc36-7bea97175fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels removed from memory.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del train_labels\n",
    "gc.collect()\n",
    "print(\"train_labels removed from memory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd15bddd-54b7-48a5-91cd-1acad907826a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499dfaae-6af1-456d-92dc-dcd1e5a4b7d0",
   "metadata": {},
   "source": [
    "### Deep learning: Validation set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291c88b2-4fe2-4216-bcac-02966189bcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: evaluate loading the raw or SMOTEd data\n",
    "val_images = np.load('data/val_images.npy')\n",
    "val_labels = np.load('data/val_labels.npy')\n",
    "val_labels = to_categorical(val_labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38b820a0-83c6-41f9-929a-9f3a67827904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step\n"
     ]
    }
   ],
   "source": [
    "with open('models/dnn_histogram_model.pkl', 'rb') as file:\n",
    "    cnn_loaded_model = pickle.load(file)\n",
    "    \n",
    "# Load precomputed bin edges\n",
    "bin_edges = np.load('cached_data/bin_edges.npy')\n",
    "\n",
    "# Convert validation images to histograms\n",
    "val_images = np.load('data/val_images.npy')\n",
    "val_histograms = np.array([image_to_histogram(img, bin_edges) for img in val_images])\n",
    "\n",
    "# Free memory\n",
    "del val_images\n",
    "gc.collect()\n",
    "\n",
    "# Now use histograms for prediction\n",
    "val_predictions = cnn_loaded_model.predict(val_histograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03f5a607-5aa3-4106-aeb7-f1dfbb534ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3237,)\n",
      "(3237,)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       727\n",
      "           1       1.00      1.00      1.00       222\n",
      "           2       1.00      1.00      1.00       421\n",
      "           3       1.00      0.95      0.98       721\n",
      "           4       1.00      1.00      1.00      1146\n",
      "\n",
      "    accuracy                           0.99      3237\n",
      "   macro avg       0.99      0.99      0.99      3237\n",
      "weighted avg       0.99      0.99      0.99      3237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Ensure val_labels is in the correct format (1D array of class indices)\n",
    "# If val_labels is one-hot encoded, convert it to class indices\n",
    "if val_labels.ndim > 1:  # Check if val_labels is one-hot encoded (2D array)\n",
    "    val_labels = np.argmax(val_labels, axis=1)\n",
    "\n",
    "# Ensure val_predictions is in the correct format (1D array of class indices)\n",
    "# If val_predictions is a 2D array of probabilities, convert it to class indices\n",
    "if val_predictions.ndim > 1:  # Check if val_predictions is a 2D array\n",
    "    val_predictions = np.argmax(val_predictions, axis=1)\n",
    "\n",
    "# Verify shapes\n",
    "print(val_predictions.shape)  # Should be (3237,)\n",
    "print(val_labels.shape)       # Should be (3237,)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_labels, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a057ecbb-bc27-4ec1-a658-3f589c64b5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "reversescale": false,
         "showscale": true,
         "type": "heatmap",
         "x": [
          "Blurry",
          "Corrupt",
          "Missing_Data",
          "Noisy",
          "Priority"
         ],
         "y": [
          "Blurry",
          "Corrupt",
          "Missing_Data",
          "Noisy",
          "Priority"
         ],
         "z": {
          "bdata": "1gIAAAAAAQAAAAAA3gAAAAAAAAAAAAAApQEAAAAAIgAAAAAArwIAAAAAAAAAAAAAegQ=",
          "dtype": "i2",
          "shape": "5, 5"
         }
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "726",
          "x": "Blurry",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Corrupt",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "1",
          "x": "Noisy",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Priority",
          "xref": "x",
          "y": "Blurry",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Blurry",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "222",
          "x": "Corrupt",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Noisy",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Priority",
          "xref": "x",
          "y": "Corrupt",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Blurry",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Corrupt",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "421",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Noisy",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Priority",
          "xref": "x",
          "y": "Missing_Data",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "34",
          "x": "Blurry",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Corrupt",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "687",
          "x": "Noisy",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Priority",
          "xref": "x",
          "y": "Noisy",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Blurry",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Corrupt",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Missing_Data",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         },
         {
          "font": {
           "color": "#000000"
          },
          "showarrow": false,
          "text": "0",
          "x": "Noisy",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         },
         {
          "font": {
           "color": "#FFFFFF"
          },
          "showarrow": false,
          "text": "1146",
          "x": "Priority",
          "xref": "x",
          "y": "Priority",
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion Matrix with Class Names"
        },
        "xaxis": {
         "dtick": 1,
         "gridcolor": "rgb(0, 0, 0)",
         "side": "top",
         "ticks": "",
         "title": {
          "text": "Predicted Label"
         }
        },
        "yaxis": {
         "dtick": 1,
         "ticks": "",
         "ticksuffix": "  ",
         "title": {
          "text": "True Label"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"]\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(val_labels, val_predictions)\n",
    "\n",
    "# Create the heatmap\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    z=cm, \n",
    "    x=class_names, \n",
    "    y=class_names, \n",
    "    colorscale=\"Blues\",\n",
    "    showscale=True\n",
    ")\n",
    "\n",
    "# Update layout for better readability\n",
    "fig.update_layout(\n",
    "    title=\"Confusion Matrix with Class Names\",\n",
    "    xaxis=dict(title=\"Predicted Label\"),\n",
    "    yaxis=dict(title=\"True Label\")\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd9ea9-aa11-4f94-be51-b406ff860735",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01be5fd-f911-410b-81e4-f0cd21f4cb4f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b614995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Histogram-Based Model:\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step\n",
      "Histogram Model Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98       668\n",
      "           1       1.00      1.00      1.00       213\n",
      "           2       1.00      1.00      1.00       414\n",
      "           3       1.00      0.96      0.98       721\n",
      "           4       1.00      1.00      1.00      1221\n",
      "\n",
      "    accuracy                           0.99      3237\n",
      "   macro avg       0.99      0.99      0.99      3237\n",
      "weighted avg       0.99      0.99      0.99      3237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import gc\n",
    "from source.evaluate import evaluate_pipeline\n",
    "\n",
    "#TODO\n",
    "def preprocessing_fn_DNN(X_test_raw):\n",
    "    \"\"\"\n",
    "    TODO: implement whole preprocessing\n",
    "    \"\"\"\n",
    "    print(f\"preprocessing_fn_DNN.X_test_raw: {X_test_raw}\")\n",
    "\n",
    "def test_models():\n",
    "    # Load test data\n",
    "    test_images = np.load('data/test_images.npy')\n",
    "    test_labels = np.load('data/test_labels.npy')\n",
    "    true_classes = test_labels  # Save original labels for reporting\n",
    "\n",
    "    # Test Histogram Model\n",
    "    print(\"\\nTesting Histogram-Based Model:\")\n",
    "\n",
    "    # Load histogram model and bin edges\n",
    "    with open('models/dnn_histogram_model.pkl', 'rb') as f:\n",
    "        hist_model = pickle.load(f)\n",
    "    \n",
    "    bin_edges = np.load('cached_data/bin_edges.npy')\n",
    "    \n",
    "    # Convert test images to histograms\n",
    "    test_histograms = np.array([image_to_histogram(img, bin_edges) for img in test_images])\n",
    "    \n",
    "    # Predict with histograms\n",
    "    hist_pred_probs = hist_model.predict(test_histograms)\n",
    "    hist_pred_classes = np.argmax(hist_pred_probs, axis=1)\n",
    "    \n",
    "    # Generate report\n",
    "    print(\"Histogram Model Report:\")\n",
    "    print(classification_report(true_classes, hist_pred_classes))\n",
    "\n",
    "    #metrics = evaluate_pipeline(hist_model, test_images, test_labels, preprocessing_fn_DNN)\n",
    "    \n",
    "\n",
    "test_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9d935-fda3-4ea3-8b33-4d5bd7cefc3a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4b49d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elapsed time: 841.425561 seconds\n"
     ]
    }
   ],
   "source": [
    "notebook_end_time = time.time()\n",
    "\n",
    "elapsed_time = notebook_end_time - notebook_start_time\n",
    "\n",
    "print(f\"Total elapsed time: {elapsed_time:.6f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
